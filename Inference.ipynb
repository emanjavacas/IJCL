{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf390852-3f3f-4d0b-822e-20b7d04bb084",
   "metadata": {},
   "source": [
    "# (Semi-)Automatic Data Annotation\n",
    "\n",
    "This notebook explains how to load a model from the huggingface transformers library and use it to label examples from a corpus sample. It also contains code to evaluate the results of the model on a test dataset.\n",
    "\n",
    "To demonstrate the procedure, we use a case study of Modern English _ing_-forms (1500-1920) and load a fine-tuned model based on the historical English MacBERTh model. The case study is described in the following article:\n",
    "\n",
    "[Insert reference here]\n",
    "\n",
    "If you are new to Jupyter notebooks (and programming in Python), we recommend Chapter 1 and 2 in [this introduction to cultural analytics and Python by Melanie Walsh](https://melaniewalsh.github.io/Intro-Cultural-Analytics/01-Command-Line/01-The-Command-Line.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a6a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/lauren/anaconda3/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy in /Users/lauren/anaconda3/lib/python3.8/site-packages (1.19.5)\n",
      "Requirement already satisfied: pandas in /Users/lauren/anaconda3/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: scikit_learn in /Users/lauren/anaconda3/lib/python3.8/site-packages (0.24.1)\n",
      "Requirement already satisfied: scipy in /Users/lauren/anaconda3/lib/python3.8/site-packages (1.6.2)\n",
      "Requirement already satisfied: torch in /Users/lauren/anaconda3/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: transformers in /Users/lauren/anaconda3/lib/python3.8/site-packages (4.20.0.dev0)\n",
      "Requirement already satisfied: xxhash in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: aiohttp in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: packaging in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /Users/lauren/anaconda3/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: filelock in /Users/lauren/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from scikit_learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from scikit_learn) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/lauren/anaconda3/lib/python3.8/site-packages (from transformers) (0.12.1)\n"
     ]
    }
   ],
   "source": [
    "# We start by installing the required libraries\n",
    "!python -m pip install datasets numpy pandas scikit_learn scipy torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b58e11f-7d1c-4267-90ed-362fc5fa8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the packages and functions you need to import to run this notebook. \n",
    "#Some packages are imported as a shorter alias.\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from finetune import read_data, encode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb2d8a-6e26-4161-8f69-9f9551c9a0e3",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "First, we should load a model (and accompanying tokenizer) from the huggingface hub. The code below loads a version of the MacBERTh model that is fine-tuned on a dataset of _ing_-forms. To fine-tune your own model, please check the 'finetune.py' and 'finetune-cv.py' scripts in this repository. \n",
    "\n",
    "In our case study, _ing_-forms are supposed to be classified by means of a custom classification scheme. The data set and classification procedure are decribed in [this article](www.article.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6cd289-7af7-4600-af6b-284f073e979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05309bade6b2441cb6a5a5d251eb1456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/956 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952c053c11184b3e855fc67b493ff718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62440ecc24aa4900a62437bb330880b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855721e7ec204b5aa46049113b8524a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244fb981112d49258ce7b1aced51a25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593814dde53745febc75c828c8f79344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1f69dd0be24ba88255d20ed3b3fb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The name of the model we load is 'emanjavacas/MacBERTh-ing'. \n",
    "#To load a different model, change the name between the single quotation marks.\n",
    "m = AutoModelForSequenceClassification.from_pretrained('emanjavacas/MacBERTh-ing')\n",
    "tokenizer = AutoTokenizer.from_pretrained('emanjavacas/MacBERTh-ing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eba370-dccb-4e8e-bf92-3b2249a83a4a",
   "metadata": {},
   "source": [
    "In the data set we use, _ing_-forms in English could be classified as one of five different types, including names and nouns that end in _ing_ (e.g. _Reading_, _something_), but also deverbal nouns (e.g. _the building_), participles (e.g. _I am working_) and verbs (e.g. _bring_, _sing_). The labels of the five-way classification scheme are given in the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1098d118-cba1-410c-b20a-f3b158fbc2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = ['NAME', 'NOMINAL-ING', 'NOUN', 'PARTICIPLE', 'VERB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906573c1-8984-4f67-ada7-24d50b0b8e7f",
   "metadata": {},
   "source": [
    "To illustrate, given an input sentence, we can use the fine-tuned model we load here for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7607b8b9-bc50-411f-ae38-2c06ed9fd881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Church about half a mile from her house, being about twenty weeks gone with Child, and to her thinking very well and healthy, upon a sudden she was taken with great pains and miscarried before she came'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, we define a particular sentence (e.g. a randomly chosen example from a corpus)\n",
    "sentence = 'Church about half a mile from her house, being about twenty weeks gone ' + \\\n",
    "'with Child, and to her thinking very well and healthy, upon a sudden she was taken ' + \\\n",
    "'with great pains and miscarried before she came'\n",
    "\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e835688c-ee7e-4337-87c3-16441e700dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.9836,  7.5749, -1.4609, -2.8214, -2.4386]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then we process the sentence\n",
    "data = tokenizer(sentence, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    output = m(**data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83173dcf-a544-4fd6-97b3-5f351ae64832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOMINAL-ING'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And finally we obtain a predicted label\n",
    "prediction = np.argmax(output.logits.numpy())\n",
    "id2label[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36045f-ffce-4473-b47a-25fb4abd4b47",
   "metadata": {},
   "source": [
    "## Adding target markers\n",
    "\n",
    "However, since more than one ing-form may occur in the sentence, we fine-tuned the model adding markers to lead the model's attention towards the token that we want predictions for. \n",
    "\n",
    "It is important that we do this also during training, since it will have a big impact on the model's performance. The following example illustrates the divergent behaviour.\n",
    "\n",
    "The markers are the `'[TGT]'` symbols before and after the target token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8db42a-9585-4a39-b4ec-e4a51ff44b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_raw = \"Every Gay thing to be a Cavalier; Every Parish - Clerk to be a Doctor; \" + \\\n",
    "\"and Every writing Clerk in the Office must be call'd Mr Secretary. So that the whole \" + \\\n",
    "\"world, take it where you will\"\n",
    "\n",
    "data = tokenizer(sentence_raw, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    output = m(**data)\n",
    "prediction = np.argmax(output.logits.numpy())\n",
    "id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a8908b0-bcd6-437f-a677-562c6eeedbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PARTICIPLE'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_marked = \"Every Gay thing to be a Cavalier; Every Parish - Clerk to be a Doctor; \" + \\\n",
    "\"and Every [TGT] writing [TGT] Clerk in the Office must be call'd Mr Secretary. So that the whole \" + \\\n",
    "\"world, take it where you will\"\n",
    "\n",
    "data = tokenizer(sentence_marked, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    output = m(**data)\n",
    "prediction = np.argmax(output.logits.numpy())\n",
    "id2label[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a16d42",
   "metadata": {},
   "source": [
    "# Evaluate predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f98d2-7a6b-44c4-9bbb-0ca030d7f3f5",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Here we load a dataset that has sentences in the format as we used them during fine-tuning. We will use these sentences and the associated labels to perform an evaluation of the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2e20c8-e317-42d3-910b-8fc846de7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test_set_ing.EMMA.merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3159617b-42de-41ce-990e-90780818111e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>docid</th>\n",
       "      <th>genre</th>\n",
       "      <th>lhs</th>\n",
       "      <th>match</th>\n",
       "      <th>rhs</th>\n",
       "      <th>level-1</th>\n",
       "      <th>level-2</th>\n",
       "      <th>level-3</th>\n",
       "      <th>comment</th>\n",
       "      <th>title</th>\n",
       "      <th>lhs-clean</th>\n",
       "      <th>rhs-clean</th>\n",
       "      <th>ing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>617966</td>\n",
       "      <td>Burnet, Gilbert</td>\n",
       "      <td>1681</td>\n",
       "      <td>10624521</td>\n",
       "      <td>prose</td>\n",
       "      <td>that which remained of the Episcopal Dignity ...</td>\n",
       "      <td>recovering</td>\n",
       "      <td>that which was lost . This was signified to C...</td>\n",
       "      <td>NOMINAL-ING</td>\n",
       "      <td>NO-OBJ-GERUND</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The history of the rights of princes in the di...</td>\n",
       "      <td>that which remained of the Episcopal Dignity ,...</td>\n",
       "      <td>that which was lost . This was signified to Ca...</td>\n",
       "      <td>recovering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index           author  year     docid  genre  \\\n",
       "0  617966  Burnet, Gilbert  1681  10624521  prose   \n",
       "\n",
       "                                                 lhs       match  \\\n",
       "0   that which remained of the Episcopal Dignity ...  recovering   \n",
       "\n",
       "                                                 rhs      level-1  \\\n",
       "0   that which was lost . This was signified to C...  NOMINAL-ING   \n",
       "\n",
       "         level-2 level-3  comment  \\\n",
       "0  NO-OBJ-GERUND       G      NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0  The history of the rights of princes in the di...   \n",
       "\n",
       "                                           lhs-clean  \\\n",
       "0  that which remained of the Episcopal Dignity ,...   \n",
       "\n",
       "                                           rhs-clean         ing  \n",
       "0  that which was lost . This was signified to Ca...  recovering  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13d02cf7-f69f-4717-905d-ae0e6a0e040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(example):\n",
    "    return ' '.join(example.split())\n",
    "\n",
    "lhs, target, rhs = 'lhs', 'match', 'rhs'\n",
    "for heading in [lhs, target, rhs]:\n",
    "    # replace NaNs with empty space\n",
    "    test[heading] = test[heading].fillna('')\n",
    "    # normalise whitespaces\n",
    "    test[heading] = test[heading].transform(normalise)\n",
    "    \n",
    "# pull sentences together\n",
    "sents, starts, ends = read_data(test[lhs], test[target], test[rhs])\n",
    "# transform into model input format\n",
    "sents, spans = encode_data(tokenizer, sents, starts, ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b022d-c181-484a-ab02-1c869f4197f3",
   "metadata": {},
   "source": [
    "## Gather predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdf9f9e5-7596-4098-ac24-82d053b2a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [02:53,  4.35s/it]                        \n"
     ]
    }
   ],
   "source": [
    "batch_size = 40\n",
    "preds, probs = [], []\n",
    "n_batches = len(sents) // batch_size\n",
    "for start in tqdm.tqdm(range(0, len(sents), batch_size), total=n_batches):\n",
    "    with torch.no_grad():\n",
    "        # input batch data\n",
    "        input_data = tokenizer(sents[start:start+batch_size], return_tensors='pt', padding=True)\n",
    "        # output from the model\n",
    "        output = m(**input_data)\n",
    "        # probabilities and predictions\n",
    "        logits = output.logits.numpy()\n",
    "        probs_ = softmax(output.logits.numpy(), axis=1)\n",
    "        preds_ = np.argmax(probs_, axis=1)\n",
    "        preds_ = [id2label[id] for id in preds_]\n",
    "        preds.extend(preds_)\n",
    "        probs.extend(probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2611861-8332-4af3-bcb0-64a2e66b9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b210825-53f9-4267-b77f-db5a67110751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NAME       1.00      0.67      0.80         6\n",
      " NOMINAL-ING       0.94      0.69      0.80       657\n",
      "        NOUN       0.72      0.84      0.78       160\n",
      "  PARTICIPLE       0.76      0.91      0.83       729\n",
      "        VERB       0.60      0.89      0.72        27\n",
      "\n",
      "    accuracy                           0.81      1579\n",
      "   macro avg       0.81      0.80      0.78      1579\n",
      "weighted avg       0.83      0.81      0.81      1579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test['level-1'].values, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b7126-57a4-4bdd-9427-e53c9ba9582b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
